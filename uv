"""å¿«é€Ÿæµ‹è¯•å„ä¸ªæ¨¡å‹æ˜¯å¦å¯ç”¨ - ä¿®å¤ç‰ˆ"""
import sherpa_onnx
from pathlib import Path
import wave
import numpy as np

print("="*60)
print("ğŸ”Š æµ‹è¯• TTS (è¯­éŸ³åˆæˆ)")
print("="*60)

# TTSæµ‹è¯•
tts_dir = Path("models/vits-melo-tts-zh_en")
config = sherpa_onnx.OfflineTtsConfig(
    model=sherpa_onnx.OfflineTtsModelConfig(
        vits=sherpa_onnx.OfflineTtsVitsModelConfig(
            model=str(tts_dir / "model.onnx"),
            tokens=str(tts_dir / "tokens.txt"),
            data_dir=str(tts_dir / "espeak-ng-data"),
        )
    ),
    max_num_sentences=1,
)

tts = sherpa_onnx.OfflineTts(config)
print(f"âœ… TTSåŠ è½½æˆåŠŸï¼Œé‡‡æ ·ç‡: {tts.sample_rate} Hz")

# ä½¿ç”¨è‹±æ–‡æµ‹è¯•ï¼ˆé¿å…ä¸­æ–‡ç¼–ç é—®é¢˜ï¼‰
text = "Hello, this is a test"
print(f"ğŸ¤ ç”Ÿæˆæ–‡æœ¬: {text}")
audio = tts.generate(text, sid=0, speed=1.0)

# ä¿®å¤: å°†listè½¬æ¢ä¸ºnumpyæ•°ç»„
if isinstance(audio.samples, list):
    audio_samples = np.array(audio.samples, dtype=np.float32)
else:
    audio_samples = audio.samples

# ä¿å­˜éŸ³é¢‘
output_file = "test_output.wav"
with wave.open(output_file, 'wb') as wf:
    wf.setnchannels(1)
    wf.setsampwidth(2)
    wf.setframerate(tts.sample_rate)
    wf.writeframes((audio_samples * 32767).astype(np.int16).tobytes())

print(f"âœ… å·²ç”Ÿæˆ: {output_file}")

# æ’­æ”¾
try:
    import winsound
    print("ğŸ”Š æ­£åœ¨æ’­æ”¾...")
    winsound.PlaySound(output_file, winsound.SND_FILENAME)
    print("âœ… æ’­æ”¾å®Œæˆ")
except Exception as e:
    print(f"âš ï¸ æ’­æ”¾å¤±è´¥: {e}")

print("\n" + "="*60)
print("ğŸ™ï¸ æµ‹è¯• STT (è¯­éŸ³è¯†åˆ«)")
print("="*60)

# STTæµ‹è¯• - æ£€æŸ¥æ–‡ä»¶
stt_dir = Path("models/sherpa-onnx-paraformer-zh-2024-03-09")
print(f"ğŸ“ STTç›®å½•: {stt_dir}")
print("ğŸ“„ ç›®å½•å†…å®¹:")
for f in stt_dir.iterdir():
    print(f"   - {f.name}")

# æŸ¥æ‰¾encoderæ–‡ä»¶
encoder_files = list(stt_dir.glob("*.onnx"))
print(f"\nğŸ” æ‰¾åˆ°çš„ONNXæ–‡ä»¶:")
for f in encoder_files:
    print(f"   - {f.name}")

if not encoder_files:
    print("âŒ æ²¡æœ‰æ‰¾åˆ°ONNXæ¨¡å‹æ–‡ä»¶")
    print("   è¯·æ£€æŸ¥ä¸‹è½½æ˜¯å¦å®Œæ•´")
else:
    # ä½¿ç”¨ç¬¬ä¸€ä¸ªæ‰¾åˆ°çš„onnxæ–‡ä»¶
    encoder = encoder_files[0]
    print(f"\nâœ… ä½¿ç”¨æ¨¡å‹: {encoder.name}")
    
    try:
        config = sherpa_onnx.OfflineRecognizerConfig(
            model_config=sherpa_onnx.OfflineModelConfig(
                paraformer=sherpa_onnx.OfflineParaformerModelConfig(
                    model=str(encoder),
                ),
                tokens=str(stt_dir / "tokens.txt"),
                num_threads=2,
            )
        )

        recognizer = sherpa_onnx.OfflineRecognizer(config)
        print(f"âœ… STTåŠ è½½æˆåŠŸï¼Œé‡‡æ ·ç‡: {recognizer.sample_rate} Hz")

        # è¯†åˆ«åˆšæ‰ç”Ÿæˆçš„éŸ³é¢‘
        print(f"ğŸ§ è¯†åˆ«éŸ³é¢‘: {output_file}")
        with wave.open(output_file, 'rb') as wf:
            samples = np.frombuffer(wf.readframes(wf.getnframes()), dtype=np.int16)
            samples = samples.astype(np.float32) / 32768.0

        stream = recognizer.create_stream()
        stream.accept_waveform(tts.sample_rate, samples)
        recognizer.decode_stream(stream)

        result = stream.result.text
        print(f"ğŸ“ è¯†åˆ«ç»“æœ: {result}")
    except Exception as e:
        print(f"âŒ STTæµ‹è¯•å¤±è´¥: {e}")

print("\n" + "="*60)
print("ğŸšï¸ æµ‹è¯• VAD (è¯­éŸ³æ´»åŠ¨æ£€æµ‹)")
print("="*60)

vad_file = Path("models/silero_vad.onnx")
config = sherpa_onnx.VadModelConfig()
config.silero_vad.model = str(vad_file)
config.sample_rate = 16000

vad = sherpa_onnx.VoiceActivityDetector(config, buffer_size_in_seconds=10)
print(f"âœ… VADåŠ è½½æˆåŠŸ")

print("\n" + "="*60)
print("ğŸ‰ æµ‹è¯•å®Œæˆï¼")
print("="*60)

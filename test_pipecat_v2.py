#!/usr/bin/env python3
"""æµ‹è¯• Pipecat v2.0 æ¶æ„"""
import asyncio
import sys
from pathlib import Path

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent.parent))


async def test_pyaudio_transport():
    """æµ‹è¯• PyAudioTransport"""
    print("=" * 60)
    print("æµ‹è¯• 1: PyAudioTransport")
    print("=" * 60)

    try:
        from src.voice_assistant.pyaudio_transport import PyAudioTransport

        transport = PyAudioTransport(sample_rate=16000)
        await transport.start()

        print("âœ“ PyAudioTransport åˆå§‹åŒ–æˆåŠŸ")
        print(f"âœ“ è¾“å…¥æµ: {transport.input_stream is not None}")
        print(f"âœ“ è¾“å‡ºæµ: {transport.output_stream is not None}")

        # æµ‹è¯• input() å’Œ output() æ–¹æ³•
        input_proc = transport.input()
        output_proc = transport.output()

        print(f"âœ“ input() è¿”å›: {type(input_proc).__name__}")
        print(f"âœ“ output() è¿”å›: {type(output_proc).__name__}")

        await transport.stop()
        print("âœ“ PyAudioTransport åœæ­¢æˆåŠŸ")

        return True

    except Exception as e:
        print(f"âŒ PyAudioTransport æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


async def test_tts_processor():
    """æµ‹è¯• PiperTTSProcessor"""
    print("\n" + "=" * 60)
    print("æµ‹è¯• 2: PiperTTSProcessor")
    print("=" * 60)

    try:
        from src.voice_assistant.tts import TTSManager
        from src.voice_assistant.pipecat_adapters import PiperTTSProcessor

        # æ£€æŸ¥ Piper æ¨¡å‹ï¼ˆä¿®æ­£è·¯å¾„ï¼‰
        model_path = Path(__file__).parent / "models" / "piper" / "zh_CN-huayan-medium.onnx"
        if not model_path.exists():
            print(f"âš ï¸ Piper æ¨¡å‹ä¸å­˜åœ¨: {model_path}")
            print("   è¯·è¿è¡Œ: python download_piper_model.py")
            return False

        tts = TTSManager(engine_type="piper", model_path=model_path)
        print(f"âœ“ TTSManager åˆå§‹åŒ–æˆåŠŸ")

        tts_proc = PiperTTSProcessor(tts)
        print(f"âœ“ PiperTTSProcessor åˆ›å»ºæˆåŠŸ")

        # æ£€æŸ¥æ˜¯å¦ä¸ä¾èµ– transport
        print("âœ“ PiperTTSProcessor ä¸ä¾èµ– transportï¼ˆæ­£ç¡®ï¼‰")

        return True

    except Exception as e:
        print(f"âŒ PiperTTSProcessor æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


async def test_vision_processor():
    """æµ‹è¯• VisionProcessor"""
    print("\n" + "=" * 60)
    print("æµ‹è¯• 3: VisionProcessor")
    print("=" * 60)

    try:
        from src.voice_assistant.pipecat_adapters import VisionProcessor
        from src.voice_assistant.qwen_llm_service import QwenLLMContext
        from src.voice_assistant.config import DASHSCOPE_API_URL, DASHSCOPE_API_KEY

        # åˆ›å»º mock context
        context = QwenLLMContext(
            messages=[{"role": "system", "content": "test"}],
            tools=[]
        )

        vision_proc = VisionProcessor(
            api_url=DASHSCOPE_API_URL,
            api_key=DASHSCOPE_API_KEY,
            context=context
        )

        print(f"âœ“ VisionProcessor åˆ›å»ºæˆåŠŸ")
        print(f"âœ“ æ¥æ”¶ context: {vision_proc.context is not None}")
        print(f"âœ“ Vision å…³é”®è¯: {len(vision_proc.vision_keywords)} ä¸ª")
        print(f"âœ“ æ“ä½œå…³é”®è¯: {len(vision_proc.operation_keywords)} ä¸ª")

        # æµ‹è¯•å…³é”®è¯åˆ¤æ–­
        assert vision_proc._needs_vision("æŸ¥çœ‹å±å¹•") == True
        assert vision_proc._needs_vision("ç‚¹å‡»æŒ‰é’®") == False
        print("âœ“ å…³é”®è¯åˆ¤æ–­é€»è¾‘æ­£ç¡®")

        return True

    except Exception as e:
        print(f"âŒ VisionProcessor æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


async def test_pipeline_structure():
    """æµ‹è¯• Pipeline ç»“æ„"""
    print("\n" + "=" * 60)
    print("æµ‹è¯• 4: Pipeline ç»“æ„")
    print("=" * 60)

    try:
        from src.voice_assistant.pyaudio_transport import PyAudioTransport
        from src.voice_assistant.pipecat_adapters import (
            SherpaKWSProcessor,
            SherpaASRProcessor,
            PiperTTSProcessor,
            VisionProcessor,
        )
        from src.voice_assistant.qwen_llm_service import QwenLLMService, QwenLLMContext
        from pipecat.services.openai.llm import (
            OpenAIUserContextAggregator,
            OpenAIAssistantContextAggregator,
        )
        from pipecat.pipeline.pipeline import Pipeline
        from src.voice_assistant.wake_word import SmartWakeWordSystem
        from src.voice_assistant.config import DASHSCOPE_API_URL, DASHSCOPE_API_KEY

        # åˆ›å»ºç»„ä»¶ï¼ˆä¸å¯åŠ¨ï¼‰
        wake_system = SmartWakeWordSystem(enable_voice=False, enable_mcp=False)

        kws_proc = SherpaKWSProcessor(wake_system.kws_model)
        asr_proc = SherpaASRProcessor(wake_system.asr_model)

        llm = QwenLLMService(model="qwen-plus")
        context = QwenLLMContext(messages=[], tools=[])

        user_agg = OpenAIUserContextAggregator(context)
        assistant_agg = OpenAIAssistantContextAggregator(context)

        vision_proc = VisionProcessor(DASHSCOPE_API_URL, DASHSCOPE_API_KEY, context)

        # ä¿®æ­£ Piper æ¨¡å‹è·¯å¾„
        model_path = Path(__file__).parent / "models" / "piper" / "zh_CN-huayan-medium.onnx"
        if not model_path.exists():
            print(f"âš ï¸ è·³è¿‡ TTS æµ‹è¯•ï¼ˆæ¨¡å‹ä¸å­˜åœ¨ï¼‰")
            return True

        from src.voice_assistant.tts import TTSManager
        tts = TTSManager(engine_type="piper", model_path=model_path)
        tts_proc = PiperTTSProcessor(tts)

        transport = PyAudioTransport(sample_rate=16000)

        # åˆ›å»º Pipelineï¼ˆå®˜æ–¹é¡ºåºï¼‰
        pipeline = Pipeline([
            transport.input(),
            kws_proc,
            asr_proc,
            user_agg,
            vision_proc,
            llm,
            assistant_agg,
            tts_proc,
            transport.output(),
        ])

        print(f"âœ“ Pipeline åˆ›å»ºæˆåŠŸ")
        print(f"âœ“ Processors æ•°é‡: {len(pipeline.processors)}")

        # éªŒè¯é¡ºåºï¼ˆè·³è¿‡ PipelineSource å’Œ PipelineSinkï¼‰
        # Pipecat ä¼šè‡ªåŠ¨æ·»åŠ è¿™äº›å¤„ç†å™¨
        expected_order = [
            "PipelineSource",           # Pipecat è‡ªåŠ¨æ·»åŠ 
            "PyAudioInputProcessor",
            "SherpaKWSProcessor",
            "SherpaASRProcessor",
            "OpenAIUserContextAggregator",
            "VisionProcessor",
            "QwenLLMService",
            "OpenAIAssistantContextAggregator",
            "PiperTTSProcessor",
            "PyAudioOutputProcessor",
            "PipelineSink",             # Pipecat è‡ªåŠ¨æ·»åŠ 
        ]

        # åªéªŒè¯æˆ‘ä»¬å…³å¿ƒçš„å¤„ç†å™¨ï¼ˆè·³è¿‡ Source å’Œ Sinkï¼‰
        user_processors = [
            p for p in pipeline.processors
            if type(p).__name__ not in ["PipelineSource", "PipelineSink"]
        ]

        expected_user_processors = [
            name for name in expected_order
            if name not in ["PipelineSource", "PipelineSink"]
        ]

        print(f"âœ“ ç”¨æˆ·å®šä¹‰çš„ Processors: {len(user_processors)} ä¸ª")

        for i, (proc, expected) in enumerate(zip(user_processors, expected_user_processors)):
            actual = type(proc).__name__
            if actual == expected:
                print(f"  {i+1}. âœ“ {actual}")
            else:
                print(f"  {i+1}. âŒ æœŸæœ› {expected}ï¼Œå®é™… {actual}")
                return False

        print("âœ“ Pipeline é¡ºåºæ­£ç¡®ï¼ˆç¬¦åˆå®˜æ–¹æ ‡å‡†ï¼‰")

        return True

    except Exception as e:
        print(f"âŒ Pipeline ç»“æ„æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


async def main():
    """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
    print("\nğŸ§ª Pipecat v2.0 æ¶æ„æµ‹è¯•")
    print("=" * 60)

    results = {
        "PyAudioTransport": await test_pyaudio_transport(),
        "PiperTTSProcessor": await test_tts_processor(),
        "VisionProcessor": await test_vision_processor(),
        "Pipeline ç»“æ„": await test_pipeline_structure(),
    }

    print("\n" + "=" * 60)
    print("ğŸ“Š æµ‹è¯•ç»“æœæ±‡æ€»")
    print("=" * 60)

    passed = sum(results.values())
    total = len(results)

    for name, result in results.items():
        status = "âœ… é€šè¿‡" if result else "âŒ å¤±è´¥"
        print(f"{status} - {name}")

    print("\n" + "=" * 60)
    print(f"æ€»è®¡: {passed}/{total} æµ‹è¯•é€šè¿‡")
    print("=" * 60)

    if passed == total:
        print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼æ¶æ„ç¬¦åˆ Pipecat æ ‡å‡†ã€‚")
        return 0
    else:
        print(f"\nâš ï¸ {total - passed} ä¸ªæµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥é…ç½®ã€‚")
        return 1


if __name__ == "__main__":
    exit_code = asyncio.run(main())
    sys.exit(exit_code)

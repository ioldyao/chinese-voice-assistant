"""Pipecat é€‚é…å™¨ - å°è£…ç°æœ‰ç»„ä»¶ä¸º Pipecat Processors"""
import asyncio
import numpy as np
from typing import Optional
from dataclasses import dataclass

from pipecat.processors.frame_processor import FrameProcessor
from pipecat.frames.frames import (
    Frame,
    AudioRawFrame,
    TextFrame,
    TTSAudioRawFrame,
    StartInterruptionFrame,
    EndFrame,
)


# ==================== è‡ªå®šä¹‰ Frame ç±»å‹ ====================

@dataclass
class WakeWordDetectedFrame(Frame):
    """å”¤é†’è¯æ£€æµ‹å¸§"""
    keyword: str
    confidence: float = 1.0


@dataclass
class ReActStepFrame(Frame):
    """React æ¨ç†æ­¥éª¤å¸§"""
    thought: str
    action: str
    action_input: dict
    observation: str
    success: bool


# ==================== Sherpa-ONNX KWS Processor ====================

class SherpaKWSProcessor(FrameProcessor):
    """
    Sherpa-ONNX KWS é€‚é…å™¨

    å°†ç°æœ‰çš„ Sherpa-ONNX KWS æ¨¡å‹å°è£…ä¸º Pipecat Processor
    å¤„ç†éŸ³é¢‘å¸§ï¼Œæ£€æµ‹å”¤é†’è¯ï¼Œè¾“å‡º WakeWordDetectedFrame
    """

    def __init__(self, kws_model):
        super().__init__()
        self.kws_model = kws_model
        self.kws_stream = kws_model.create_stream()
        self.sample_rate = 16000
        self.is_awake = False  # ç”¨äºå¹¶è¡Œ Pipeline çš„æ¡ä»¶åˆ¤æ–­

    async def process_frame(self, frame, direction):
        """å¤„ç†éŸ³é¢‘å¸§ï¼Œæ£€æµ‹å”¤é†’è¯"""
        await super().process_frame(frame, direction)

        if isinstance(frame, AudioRawFrame):
            # æå–éŸ³é¢‘æ•°æ®
            audio_data = np.frombuffer(frame.audio, dtype=np.int16).astype(np.float32) / 32768.0

            # å–‚å…¥ KWS æ¨¡å‹
            self.kws_stream.accept_waveform(self.sample_rate, audio_data)

            # æ£€æµ‹å…³é”®è¯
            while self.kws_model.is_ready(self.kws_stream):
                self.kws_model.decode_stream(self.kws_stream)

            result = self.kws_model.get_result(self.kws_stream)

            if result:
                print(f"ğŸ”” æ£€æµ‹åˆ°å”¤é†’è¯: {result}")
                self.is_awake = True

                # å‘å‡ºå”¤é†’äº‹ä»¶
                await self.push_frame(
                    WakeWordDetectedFrame(keyword=result),
                    direction
                )

                # é‡ç½® KWS æµ
                self.kws_stream = self.kws_model.create_stream()

            # ç»§ç»­ä¼ é€’éŸ³é¢‘å¸§ï¼ˆä¾›åç»­å¤„ç†å™¨ä½¿ç”¨ï¼‰
            await self.push_frame(frame, direction)
        else:
            # å…¶ä»–å¸§ç›´æ¥ä¼ é€’
            await self.push_frame(frame, direction)


# ==================== Sherpa-ONNX ASR Processor ====================

class SherpaASRProcessor(FrameProcessor):
    """
    Sherpa-ONNX ASR é€‚é…å™¨

    å°†ç°æœ‰çš„ Sherpa-ONNX ASR æ¨¡å‹å°è£…ä¸º Pipecat Processor
    æ£€æµ‹åˆ°å”¤é†’è¯åå¼€å§‹å½•éŸ³ï¼Œä½¿ç”¨é™éŸ³æ£€æµ‹è‡ªåŠ¨åœæ­¢ï¼Œè¾“å‡ºè¯†åˆ«æ–‡æœ¬
    """

    def __init__(self, asr_model, sample_rate=16000):
        super().__init__()
        self.asr_model = asr_model
        self.sample_rate = sample_rate

        # å½•éŸ³çŠ¶æ€
        self.recording = False
        self.buffer = []

        # é™éŸ³æ£€æµ‹å‚æ•°ï¼ˆä¸åŸæœ‰é€»è¾‘ä¸€è‡´ï¼‰
        self.silence_threshold = 0.02
        self.max_silence_frames = 20  # çº¦ 1.3 ç§’
        self.min_record_frames = 15   # æœ€å°å½•éŸ³ä¿æŠ¤

        self.silence_count = 0
        self.has_speech = False
        self.frame_count = 0

    async def process_frame(self, frame, direction):
        """å¤„ç†éŸ³é¢‘å¸§ï¼Œè¯†åˆ«è¯­éŸ³"""
        await super().process_frame(frame, direction)

        # æ£€æµ‹å”¤é†’è¯ï¼Œå¼€å§‹å½•éŸ³
        if isinstance(frame, WakeWordDetectedFrame):
            print("ğŸ“ å¼€å§‹å½•éŸ³è¯†åˆ«...")
            self.recording = True
            self.buffer = []
            self.silence_count = 0
            self.has_speech = False
            self.frame_count = 0

            # ä¼ é€’å”¤é†’å¸§
            await self.push_frame(frame, direction)
            return

        # å½•éŸ³è¿‡ç¨‹
        if self.recording and isinstance(frame, AudioRawFrame):
            # æå–éŸ³é¢‘æ•°æ®
            audio_data = np.frombuffer(frame.audio, dtype=np.int16).astype(np.float32) / 32768.0
            self.buffer.append(audio_data)
            self.frame_count += 1

            # è®¡ç®—éŸ³é‡
            volume = np.sqrt(np.mean(audio_data**2))

            # é™éŸ³æ£€æµ‹
            if volume >= self.silence_threshold:
                self.has_speech = True
                self.silence_count = 0
            else:
                self.silence_count += 1

            # åœæ­¢æ¡ä»¶ï¼šæœ‰è¯­éŸ³ + è¿ç»­é™éŸ³ + è¶…è¿‡æœ€å°ä¿æŠ¤å¸§
            if (self.has_speech and
                self.silence_count > self.max_silence_frames and
                self.frame_count > self.min_record_frames):

                # æ‹¼æ¥éŸ³é¢‘
                full_audio = np.concatenate(self.buffer)

                # ASR è¯†åˆ«
                text = await self._recognize_async(full_audio)

                if text:
                    print(f"âœ“ è¯†åˆ«ç»“æœ: {text}")
                    await self.push_frame(
                        TextFrame(text=text),
                        direction
                    )

                # é‡ç½®çŠ¶æ€
                self.recording = False
                self.buffer = []

            # ç»§ç»­ä¼ é€’éŸ³é¢‘å¸§
            await self.push_frame(frame, direction)
        else:
            # å…¶ä»–å¸§ç›´æ¥ä¼ é€’
            await self.push_frame(frame, direction)

    async def _recognize_async(self, audio_data):
        """å¼‚æ­¥ ASR è¯†åˆ«ï¼ˆåœ¨çº¿ç¨‹æ± ä¸­æ‰§è¡Œï¼‰"""
        def _recognize_sync():
            # åˆ›å»º ASR æµ
            asr_stream = self.asr_model.create_stream()
            asr_stream.accept_waveform(self.sample_rate, audio_data)
            self.asr_model.decode_stream(asr_stream)
            return asr_stream.result.text.strip()

        # åœ¨çº¿ç¨‹æ± ä¸­æ‰§è¡Œï¼ˆé¿å…é˜»å¡äº‹ä»¶å¾ªç¯ï¼‰
        return await asyncio.to_thread(_recognize_sync)


# ==================== React Agent Processor ====================

class ReactAgentProcessor(FrameProcessor):
    """
    React Agent Processor - åŸºäº MCP å®˜æ–¹æ¨èæ¨¡å¼

    ä½¿ç”¨å®Œå…¨å¼‚æ­¥çš„å®ç°ï¼š
    - ç›´æ¥è°ƒç”¨ agent.execute_command_async()
    - åœ¨ä¸»äº‹ä»¶å¾ªç¯ä¸­æ‰§è¡Œ MCP è°ƒç”¨
    - åå°ä»»åŠ¡æ‰§è¡Œï¼Œä¸é˜»å¡ Pipeline
    """

    def __init__(self, react_agent):
        """
        åˆå§‹åŒ– React Agent Processor

        Args:
            react_agent: ReactAgent å®ä¾‹ï¼ˆå·²åˆå§‹åŒ– MCPï¼‰
        """
        super().__init__()
        self.agent = react_agent
        self.current_task = None
        self.cancel_flag = False

    async def process_frame(self, frame, direction):
        """å¤„ç†å¸§"""
        await super().process_frame(frame, direction)

        # æ£€æŸ¥å”¤é†’è¯ï¼Œå–æ¶ˆå½“å‰ä»»åŠ¡
        if isinstance(frame, WakeWordDetectedFrame):
            if self.current_task and not self.current_task.done():
                print("â¸ï¸  æ£€æµ‹åˆ°æ–°å”¤é†’è¯ï¼Œå–æ¶ˆå½“å‰ Agent ä»»åŠ¡")
                self.cancel_flag = True
                self.current_task.cancel()
            await self.push_frame(frame, direction)
            return

        # å¤„ç†æ–‡æœ¬å‘½ä»¤
        if isinstance(frame, TextFrame):
            print(f"ğŸ¤– React Agent å¤„ç†: {frame.text}")
            self.cancel_flag = False

            # åˆ›å»ºåå°ä»»åŠ¡ï¼ˆä¸ç­‰å¾…å®Œæˆï¼‰
            self.current_task = asyncio.create_task(
                self._execute_and_push_result(frame.text, direction)
            )

            # ç«‹å³ä¼ é€’å¸§ï¼Œä¸é˜»å¡ Pipeline
            await self.push_frame(frame, direction)
        else:
            # å…¶ä»–å¸§ç›´æ¥ä¼ é€’
            await self.push_frame(frame, direction)

    async def _execute_and_push_result(self, command: str, direction):
        """
        æ‰§è¡Œå‘½ä»¤å¹¶æ¨é€ç»“æœï¼ˆåå°ä»»åŠ¡ï¼‰

        åŸºäº MCP å®˜æ–¹æ¨èæ¨¡å¼ï¼šç›´æ¥å¼‚æ­¥è°ƒç”¨ï¼Œæ— éœ€çº¿ç¨‹
        """
        try:
            print(f"âœ¨ å¼€å§‹æ‰§è¡Œå‘½ä»¤: {command}")

            # ä½¿ç”¨å®˜æ–¹æ¨èçš„å¼‚æ­¥æ–¹å¼ç›´æ¥è°ƒç”¨
            result = await self.agent.execute_command_async(command, enable_voice=False)

            print(f"âœ… æ‰§è¡Œå®Œæˆ: success={result.get('success')}")

            # æ£€æŸ¥æ˜¯å¦è¢«å–æ¶ˆ
            if self.cancel_flag:
                print("â¸ï¸  ä»»åŠ¡å·²å–æ¶ˆï¼Œä¸æ¨é€ç»“æœ")
                return

            # æ¨é€ç»“æœæ–‡æœ¬ï¼ˆå¦‚æœæˆåŠŸï¼‰
            if result.get("success") and result.get("message"):
                result_frame = TextFrame(result["message"])
                await self.push_frame(result_frame, direction)

        except asyncio.CancelledError:
            print("â¸ï¸  ä»»åŠ¡è¢«å–æ¶ˆ")
            raise
        except Exception as e:
            print(f"âŒ æ‰§è¡Œå¼‚å¸¸: {e}")
            import traceback
            traceback.print_exc()



# ==================== Piper TTS Processor ====================

class PiperTTSProcessor(FrameProcessor):
    """
    Piper TTS é€‚é…å™¨

    å°†ç°æœ‰çš„ TTSManagerStreaming å°è£…ä¸º Pipecat Processor
    æ¥æ”¶æ–‡æœ¬å¸§ï¼Œç”ŸæˆéŸ³é¢‘å¸§å¹¶ç›´æ¥æ’­æ”¾ï¼Œæ”¯æŒä¸­æ–­
    """

    def __init__(self, tts_manager, transport=None):
        super().__init__()
        self.tts = tts_manager
        self.transport = transport  # ç”¨äºç›´æ¥æ’­æ”¾éŸ³é¢‘
        self.interrupt_flag = False  # ä¸­æ–­æ ‡å¿—

    def interrupt(self):
        """ä¸­æ–­å½“å‰TTSæ’­æ”¾"""
        self.interrupt_flag = True

    async def process_frame(self, frame, direction):
        """å¤„ç†æ–‡æœ¬å¸§ï¼Œç”Ÿæˆ TTS éŸ³é¢‘"""
        await super().process_frame(frame, direction)

        # æ£€æµ‹å”¤é†’è¯ï¼Œè®¾ç½®ä¸­æ–­
        if isinstance(frame, WakeWordDetectedFrame):
            print("â¸ï¸  æ£€æµ‹åˆ°æ–°å”¤é†’è¯ï¼Œä¸­æ–­TTSæ’­æ”¾")
            self.interrupt()
            # ä¼ é€’å”¤é†’å¸§
            await self.push_frame(frame, direction)
            return

        if isinstance(frame, TextFrame):
            print(f"ğŸ”Š TTS åˆæˆ: {frame.text}")

            # é‡ç½®ä¸­æ–­æ ‡å¿—
            self.interrupt_flag = False

            # åœ¨çº¿ç¨‹æ± ä¸­ç”Ÿæˆå’Œæ’­æ”¾éŸ³é¢‘
            await asyncio.to_thread(
                self._synthesize_and_play_sync,
                frame.text
            )

            # ä¼ é€’åŸå§‹æ–‡æœ¬å¸§
            await self.push_frame(frame, direction)
        else:
            # å…¶ä»–å¸§ç›´æ¥ä¼ é€’
            await self.push_frame(frame, direction)

    def _synthesize_and_play_sync(self, text):
        """åŒæ­¥ TTS åˆæˆå¹¶æ’­æ”¾ï¼ˆåœ¨çº¿ç¨‹æ± ä¸­æ‰§è¡Œï¼‰ï¼Œæ”¯æŒä¸­æ–­"""
        if self.tts.engine_type == "piper":
            try:
                # ä½¿ç”¨ Piper TTS ç”ŸæˆéŸ³é¢‘
                audio_generator = self.tts.piper_voice.synthesize(text)

                for chunk in audio_generator:
                    # æ£€æŸ¥ä¸­æ–­æ ‡å¿—
                    if self.interrupt_flag:
                        print("â¸ï¸  TTS æ’­æ”¾å·²ä¸­æ–­")
                        break

                    # æå–éŸ³é¢‘æ•°æ®
                    audio_float = chunk.audio_float_array
                    sample_rate = chunk.sample_rate

                    # è½¬æ¢ä¸º int16
                    audio_int16 = (audio_float * 32767).astype(np.int16)

                    # ç›´æ¥æ’­æ”¾åˆ° transport
                    if self.transport and self.transport.output_stream:
                        self.transport.output_stream.write(audio_int16.tobytes())

            except Exception as e:
                print(f"âŒ TTS ç”Ÿæˆå¤±è´¥: {e}")

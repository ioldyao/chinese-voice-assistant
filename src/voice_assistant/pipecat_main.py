"""Pipecat ä¸»ç¨‹åº - åŸºäº Pipeline æ¶æ„çš„è¯­éŸ³åŠ©æ‰‹"""
import asyncio
import signal
import sys
from pathlib import Path

from pipecat.pipeline.pipeline import Pipeline
from pipecat.pipeline.runner import PipelineRunner
from pipecat.pipeline.task import PipelineTask, PipelineParams
from pipecat.transports.base_transport import TransportParams
from pipecat.audio.vad.silero import SileroVADAnalyzer

# å¯¼å…¥é€‚é…å™¨
from .pipecat_adapters import (
    SherpaKWSProcessor,
    SherpaASRProcessor,
    PiperTTSProcessor,
    ScreenshotProcessor,
    QwenVisionProcessor,
)

# å¯¼å…¥ Qwen LLM Serviceï¼ˆå®˜æ–¹æ¡†æ¶ï¼‰
from .qwen_llm_service import (
    QwenLLMService,
    QwenLLMContext,
    mcp_tools_to_openai_format,
    register_mcp_functions,
)

# å¯¼å…¥å®˜æ–¹ Context Aggregatorï¼ˆä½¿ç”¨ OpenAI ç‰¹å®šå®ç°ï¼‰
from pipecat.services.openai.llm import (
    OpenAIUserContextAggregator,      # âœ… æ”¯æŒå‡½æ•°è°ƒç”¨å¤„ç†
    OpenAIAssistantContextAggregator, # âœ… è‡ªåŠ¨ä¿å­˜ tool_calls + ç»“æœåˆ° context
)

# å¯¼å…¥ç°æœ‰ç»„ä»¶
from .wake_word import SmartWakeWordSystem
from .config import MODELS_DIR


class SimplePyAudioTransport:
    """
    ç®€åŒ–çš„ PyAudio Transport

    åœ¨ Phase 1 ä¸­ï¼Œæˆ‘ä»¬ä½¿ç”¨ç®€åŒ–çš„éŸ³é¢‘ä¼ è¾“å®ç°
    ç›´æ¥ä½¿ç”¨ PyAudio è¿›è¡ŒéŸ³é¢‘ I/O
    """

    def __init__(self, sample_rate=16000, channels=1):
        import pyaudio
        import numpy as np

        self.pyaudio = pyaudio  # ä¿å­˜æ¨¡å—å¼•ç”¨
        self.np = np
        self.sample_rate = sample_rate
        self.channels = channels
        self.chunk_size = 512

        self.p = pyaudio.PyAudio()
        self.input_stream = None
        self.output_stream = None

        self.running = False
        self._input_queue = asyncio.Queue()
        self._output_queue = asyncio.Queue()

    async def start(self):
        """å¯åŠ¨éŸ³é¢‘ä¼ è¾“"""
        self.running = True

        # å¯åŠ¨è¾“å…¥æµ
        self.input_stream = self.p.open(
            format=self.pyaudio.paInt16,
            channels=self.channels,
            rate=self.sample_rate,
            input=True,
            frames_per_buffer=self.chunk_size,
            stream_callback=None
        )

        # å¯åŠ¨è¾“å‡ºæµ
        self.output_stream = self.p.open(
            format=self.pyaudio.paInt16,
            channels=self.channels,
            rate=self.sample_rate,
            output=True,
            frames_per_buffer=self.chunk_size
        )

        print("âœ“ éŸ³é¢‘ä¼ è¾“å·²å¯åŠ¨")

    async def stop(self):
        """åœæ­¢éŸ³é¢‘ä¼ è¾“"""
        self.running = False

        if self.input_stream:
            self.input_stream.stop_stream()
            self.input_stream.close()

        if self.output_stream:
            self.output_stream.stop_stream()
            self.output_stream.close()

        self.p.terminate()
        print("âœ“ éŸ³é¢‘ä¼ è¾“å·²åœæ­¢")

    async def read_audio_frames(self):
        """è¯»å–éŸ³é¢‘å¸§ï¼ˆç”Ÿæˆå™¨ï¼‰"""
        from pipecat.frames.frames import AudioRawFrame

        while self.running:
            try:
                # ä»éº¦å…‹é£è¯»å–éŸ³é¢‘
                audio_bytes = await asyncio.to_thread(
                    self.input_stream.read,
                    self.chunk_size,
                    exception_on_overflow=False
                )

                # åˆ›å»ºéŸ³é¢‘å¸§
                frame = AudioRawFrame(
                    audio=audio_bytes,
                    sample_rate=self.sample_rate,
                    num_channels=self.channels
                )

                yield frame

            except Exception as e:
                print(f"âŒ éŸ³é¢‘è¯»å–é”™è¯¯: {e}")
                break

    async def write_audio_frame(self, frame):
        """å†™å…¥éŸ³é¢‘å¸§åˆ°æ‰¬å£°å™¨"""
        from pipecat.frames.frames import TTSAudioRawFrame

        if isinstance(frame, TTSAudioRawFrame) and self.output_stream:
            try:
                await asyncio.to_thread(
                    self.output_stream.write,
                    frame.audio
                )
            except Exception as e:
                print(f"âŒ éŸ³é¢‘æ’­æ”¾é”™è¯¯: {e}")


async def create_pipecat_pipeline():
    """
    åˆ›å»º Pipecat Pipeline - æ··åˆæ¶æ„ç‰ˆ

    ä¿ç•™è‡ªå®šä¹‰ï¼ˆå®˜æ–¹ä¸æ”¯æŒï¼‰ï¼š
    - KWS å”¤é†’è¯æ£€æµ‹ï¼ˆSherpa-ONNXï¼‰
    - ASR æœ¬åœ°è¯†åˆ«ï¼ˆSherpa-ONNXï¼‰
    - Piper TTSï¼ˆæœ¬åœ°ã€å…è´¹ï¼‰
    - Qwen Visionï¼ˆä¿æŒç°æœ‰ APIï¼‰

    æ”¹ç”¨å®˜æ–¹ï¼ˆäº«å—å®˜æ–¹ç”Ÿæ€ï¼‰ï¼š
    - QwenLLMServiceï¼ˆç»§æ‰¿ OpenAILLMServiceï¼‰
    - LLMContextAggregatorPairï¼ˆè‡ªåŠ¨ç®¡ç†å¯¹è¯å†å²ï¼‰
    - Function Callingï¼ˆMCP å·¥å…·æ— ç¼é›†æˆï¼‰

    Pipeline ç»“æ„ï¼š
    éº¦å…‹é£ â†’ KWS â†’ ASR â†’ context.user() â†’ Screenshot â†’ Vision â†’ LLM â†’ context.assistant() â†’ TTS â†’ æ‰¬å£°å™¨
                                â†“                                 â†“
                         æ·»åŠ ç”¨æˆ·æ¶ˆæ¯                       ä¿å­˜åŠ©æ‰‹å“åº”
    """
    print("\n" + "="*60)
    print("ğŸš€ Pipecat æ¨¡å¼ - æ··åˆæ¶æ„ç‰ˆ - åˆå§‹åŒ–ä¸­...")
    print("="*60)

    # 1. åˆå§‹åŒ–ç°æœ‰ç»„ä»¶
    print("\nâ³ æ­£åœ¨åŠ è½½æ¨¡å‹...")

    # åˆ›å»º wake_word ç³»ç»Ÿï¼ˆè·³è¿‡ MCP åˆå§‹åŒ–ï¼Œé¿å…äº‹ä»¶å¾ªç¯å†²çªï¼‰
    wake_system = SmartWakeWordSystem(enable_voice=False, enable_mcp=False)

    # æ‰‹åŠ¨å¼‚æ­¥å¯åŠ¨ MCP Servers
    print("\nâ³ æ­£åœ¨å¯åŠ¨ MCP Serversï¼ˆå¼‚æ­¥æ¨¡å¼ï¼‰...")

    # åˆ›å»ºç‹¬ç«‹çš„ MCP Managerï¼ˆä¸ä½¿ç”¨ wake_system.agent.mcpï¼‰
    from .mcp_client import MCPManager
    mcp = MCPManager()

    servers = [
        # Playwright-MCP: æµè§ˆå™¨æ“ä½œï¼ˆä¸»è¦ä½¿ç”¨ï¼‰
        ("playwright", "npx", ["@playwright/mcp@latest"], 120)
    ]

    success_count = 0
    for name, command, args, timeout in servers:
        try:
            success = await mcp.add_server_async(name, command, args, timeout)
            if success:
                success_count += 1
                print(f"  âœ“ {name} MCP Server å¯åŠ¨æˆåŠŸ")
        except Exception as e:
            print(f"  âŒ {name} Server å¯åŠ¨å¼‚å¸¸: {e}")
            continue

    if success_count > 0:
        print(f"\nâœ… æˆåŠŸå¯åŠ¨ {success_count}/{len(servers)} ä¸ª MCP Server\n")

        # è·å–å·¥å…·åˆ—è¡¨ï¼ˆä½¿ç”¨å¼‚æ­¥æ–¹æ³•ï¼‰
        mcp_tools = await mcp.list_all_tools_async()
        playwright_tools = [
            tool for tool in mcp_tools
            if tool.get("server") == "playwright"
        ]
        if playwright_tools:
            print(f"  âœ“ Playwright-MCP: {len(playwright_tools)} ä¸ªå·¥å…·")

            # é‡ç‚¹æ‰“å° browser_snapshot å’Œ browser_click
            for tool in playwright_tools:
                if 'snapshot' in tool['name'] or 'click' in tool['name']:
                    print(f"\n    ğŸ“Œ {tool['name']}:")
                    print(f"       æè¿°: {tool.get('description', 'N/A')}")
                    print(f"       å‚æ•°: {list(tool.get('input_schema', {}).get('properties', {}).keys())}")
    else:
        print(f"\nâŒ æ‰€æœ‰ MCP Server å¯åŠ¨å¤±è´¥\n")
        raise RuntimeError("MCP Server å¯åŠ¨å¤±è´¥")

    # 2. åˆå§‹åŒ– Qwen LLM Serviceï¼ˆå®˜æ–¹æ¡†æ¶ï¼‰
    print("\nâ³ æ­£åœ¨åˆå§‹åŒ– Qwen LLM Serviceï¼ˆå®˜æ–¹æ¡†æ¶ï¼‰...")

    llm = QwenLLMService(model="qwen-plus")

    # æ³¨å†Œ MCP å‡½æ•°å¤„ç†å™¨
    await register_mcp_functions(llm, mcp)

    # åˆ›å»º Toolsï¼ˆOpenAI API æ ¼å¼ï¼Œç”¨äº LLM Contextï¼‰
    tools = mcp_tools_to_openai_format(mcp_tools)

    print(f"\nğŸ”§ è½¬æ¢ä¸º OpenAI æ ¼å¼å: {len(tools)} ä¸ªå·¥å…·")
    for tool in tools[:5]:  # åªæ‰“å°å‰5ä¸ª
        print(f"  - {tool['function']['name']}: {tool['function']['description'][:60]}...")

    # åˆ›å»ºå¯¹è¯ä¸Šä¸‹æ–‡
    messages = [
        {
            "role": "system",
            "content": """ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½è¯­éŸ³åŠ©æ‰‹ï¼Œå¯ä»¥ä½¿ç”¨æµè§ˆå™¨å·¥å…·å’Œè§†è§‰ç†è§£èƒ½åŠ›å¸®åŠ©ç”¨æˆ·ã€‚

å¯ç”¨å·¥å…·ï¼š
- Playwright æµè§ˆå™¨æ“ä½œï¼ˆå¯¼èˆªã€ç‚¹å‡»ã€è¾“å…¥ã€æ»šåŠ¨ç­‰ï¼‰

èƒ½åŠ›ï¼š
- è§†è§‰ç†è§£ï¼šå¯ä»¥çœ‹åˆ°å¹¶æè¿°å±å¹•å†…å®¹

é‡è¦è§„åˆ™ï¼š
1. **æ“ä½œåœºæ™¯**ï¼ˆç”¨æˆ·è¦æ±‚"æ‰“å¼€"ã€"ç‚¹å‡»"ã€"è¾“å…¥"ç­‰ï¼‰ï¼š
   - **ç‚¹å‡»å…ƒç´ å‰å¿…é¡»å…ˆè°ƒç”¨ browser_snapshot è·å–æœ€æ–°é¡µé¢å¿«ç…§**
   - ä½¿ç”¨å¿«ç…§ä¸­çš„ ref ç¼–å·è¿›è¡Œç‚¹å‡»æ“ä½œ
   - å¦‚æœç‚¹å‡»å¤±è´¥ï¼ˆref not foundï¼‰ï¼Œç«‹å³é‡æ–°è°ƒç”¨ browser_snapshot è·å–æ–°å¿«ç…§
   - å·¥å…·è°ƒç”¨æˆåŠŸåï¼Œç”¨ç®€çŸ­çš„ä¸­æ–‡ç¡®è®¤ï¼ˆå¦‚"å¥½çš„ï¼Œå·²ç»ç‚¹å‡»"ï¼‰
   - ä¸è¦é‡å¤è°ƒç”¨åŒä¸€ä¸ªå·¥å…·

2. **è§†è§‰ç†è§£åœºæ™¯**ï¼ˆç”¨æˆ·è¦æ±‚"æŸ¥çœ‹"ã€"çœ‹"ã€"æè¿°"ç­‰ï¼‰ï¼š
   - å¦‚æœæ”¶åˆ° `[è§†è§‰è§‚å¯Ÿ]` å¼€å¤´çš„æ¶ˆæ¯ï¼Œè¯´æ˜ç³»ç»Ÿå·²ç»å®Œæˆæˆªå›¾å’Œè§†è§‰åˆ†æ
   - ç”¨è‡ªç„¶ã€ç®€æ´çš„è¯­è¨€å‘ç”¨æˆ·æè¿°å±å¹•å†…å®¹
   - çªå‡ºå…³é”®ä¿¡æ¯ï¼Œå‡†ç¡®æè¿°ç”»é¢å†…å®¹

3. **æ‰§è¡Œæµç¨‹ç¤ºä¾‹**ï¼š
   ç”¨æˆ·ï¼š"ç‚¹å‡»åŠ¨æ€æŒ‰é’®"
   â†’ æ­¥éª¤1ï¼šè°ƒç”¨ browser_snapshotï¼ˆè·å–é¡µé¢å…ƒç´ å’Œrefï¼‰
   â†’ æ­¥éª¤2ï¼šè°ƒç”¨ browser_clickï¼ˆä½¿ç”¨å¿«ç…§ä¸­çš„refç‚¹å‡»ï¼‰
   â†’ æ­¥éª¤3ï¼šå›å¤"å¥½çš„ï¼Œå·²ç»ç‚¹å‡»"

4. ä¸è¦ä¸»åŠ¨è¯¢é—®ç”¨æˆ·æ˜¯å¦éœ€è¦å…¶ä»–å¸®åŠ©"""
        }
    ]

    context = QwenLLMContext(messages, tools=tools)

    print(f"\nğŸ“‹ LLMContext ä¸­çš„ tools: {len(context.tools) if context.tools else 0} ä¸ª")
    if context.tools:
        for tool in context.tools[:3]:  # æ‰“å°å‰3ä¸ª
            print(f"  - {tool['function']['name']}")

    # åˆ›å»º User Context Aggregatorï¼ˆæ·»åŠ ç”¨æˆ·æ¶ˆæ¯åˆ°ä¸Šä¸‹æ–‡ï¼‰
    user_aggregator = OpenAIUserContextAggregator(context)

    # âœ… åˆ›å»º Assistant Context Aggregatorï¼ˆä¿å­˜å·¥å…·è°ƒç”¨å†å²ï¼‰
    assistant_aggregator = OpenAIAssistantContextAggregator(context)

    print("âœ“ QwenLLMService å·²åˆå§‹åŒ–")
    print("âœ“ MCP å‡½æ•°å·²æ³¨å†Œ")
    print("âœ“ OpenAIUserContextAggregator å·²åˆ›å»º")
    print("âœ“ OpenAIAssistantContextAggregator å·²åˆ›å»º")

    # 3. åˆ›å»º Pipecat Processors
    print("\nâ³ æ­£åœ¨åˆ›å»º Pipecat Processors...")

    kws_proc = SherpaKWSProcessor(wake_system.kws_model)
    asr_proc = SherpaASRProcessor(wake_system.asr_model)

    # Vision Processorsï¼ˆé‡‡ç”¨ Pipecat å®˜æ–¹æ¨¡å¼ï¼‰
    screenshot_proc = ScreenshotProcessor()  # æˆªå›¾ â†’ UserImageRawFrame
    qwen_vision_proc = QwenVisionProcessor(
        api_url=wake_system.agent.api_url,
        api_key=wake_system.agent.api_key
    )  # å¤„ç† UserImageRawFrame â†’ TextFrame

    # åˆ›å»ºéŸ³é¢‘ä¼ è¾“ï¼ˆåœ¨åˆ›å»º TTS Processor ä¹‹å‰ï¼‰
    print("\nâ³ æ­£åœ¨åˆ›å»ºéŸ³é¢‘ä¼ è¾“...")
    transport = SimplePyAudioTransport(sample_rate=16000)
    await transport.start()

    # åˆ›å»º TTS Processorï¼ˆä¼ å…¥ transport ç”¨äºéŸ³é¢‘è¾“å‡ºï¼‰
    tts_proc = PiperTTSProcessor(wake_system.agent.tts, transport)

    print("âœ“ KWS Processor å·²åˆ›å»ºï¼ˆè‡ªå®šä¹‰ï¼‰")
    print("âœ“ ASR Processor å·²åˆ›å»ºï¼ˆè‡ªå®šä¹‰ï¼‰")
    print("âœ“ Screenshot Processor å·²åˆ›å»ºï¼ˆPipecat å®˜æ–¹æ¨¡å¼ï¼‰")
    print("âœ“ Qwen Vision Processor å·²åˆ›å»ºï¼ˆPipecat å®˜æ–¹æ¨¡å¼ï¼‰")
    print("âœ“ TTS Processor å·²åˆ›å»ºï¼ˆè‡ªå®šä¹‰ï¼šPiperï¼‰")

    # 4. æ„å»º Pipelineï¼ˆæ··åˆæ¶æ„ï¼‰
    print("\nâ³ æ­£åœ¨æ„å»º Pipelineï¼ˆæ··åˆæ¶æ„ï¼‰...")

    pipeline = Pipeline([
        kws_proc,                       # è‡ªå®šä¹‰ï¼šKWS å”¤é†’è¯æ£€æµ‹
        asr_proc,                       # è‡ªå®šä¹‰ï¼šASR æœ¬åœ°è¯†åˆ«
        screenshot_proc,                # âœ… åœ¨ user_aggregator ä¹‹å‰åˆ¤æ–­ Vision
        qwen_vision_proc,               # âœ… å¤„ç† Vision è¯·æ±‚
        user_aggregator,                # å®˜æ–¹ï¼šæ·»åŠ ç”¨æˆ·æ¶ˆæ¯åˆ°ä¸Šä¸‹æ–‡ âœ¨
        llm,                            # å®˜æ–¹ï¼šQwen LLM Serviceï¼ˆå·²æ³¨å†Œ MCP å‡½æ•°ï¼‰âœ¨
        tts_proc,                       # âœ… å…ˆå¤„ç† TTSï¼ˆåœ¨ assistant_aggregator ä¹‹å‰ï¼‰
        assistant_aggregator,           # âœ… å†ä¿å­˜åˆ° contextï¼ˆå·¥å…·è°ƒç”¨å†å²ï¼‰
    ])

    print("âœ“ Pipeline å·²æ„å»º")
    print("\n" + "="*60)
    print("âœ“ Pipecat æ··åˆæ¶æ„å¯åŠ¨å®Œæˆï¼")
    print("="*60)
    print("\nğŸ“‹ Pipeline ç»“æ„ï¼ˆæ··åˆæ¶æ„ï¼‰:")
    print("   è‡ªå®šä¹‰ï¼šKWS â†’ ASR â†’ Screenshot â†’ Vision âœ¨")
    print("   å®˜æ–¹ï¼š  context.user() âœ¨")
    print("   å®˜æ–¹ï¼š  LLM Service + Function Calling âœ¨")
    print("   è‡ªå®šä¹‰ï¼šPiper TTSï¼ˆå…ˆæ’­æ”¾ï¼‰")
    print("   å®˜æ–¹ï¼š  context.assistant()ï¼ˆå†ä¿å­˜å†å²ï¼‰âœ¨")
    print("\nğŸ’¡ æŠ€æœ¯äº®ç‚¹:")
    print("   âœ… LLM Service è‡ªåŠ¨ç®¡ç†å¯¹è¯å†å²")
    print("   âœ… MCP å·¥å…·é€šè¿‡ Function Calling æ— ç¼é›†æˆ")
    print("   âœ… ä¿ç•™æœ¬åœ° KWS + ASR + TTSï¼ˆå…è´¹ã€æ— ç½‘ç»œä¾èµ–ï¼‰")
    print("   âœ… Assistant Aggregator ä¿å­˜å·¥å…·è°ƒç”¨å†å²")
    print("   âœ… TTS åœ¨ aggregator ä¹‹å‰å¤„ç†ï¼Œä¿è¯è¯­éŸ³è¾“å‡º")
    print("\nğŸ’¬ è¯´å‡ºå”¤é†’è¯å¼€å§‹å¯¹è¯...")
    print("   é»˜è®¤å”¤é†’è¯: å°æ™ºã€ä½ å¥½åŠ©æ‰‹ã€æ™ºèƒ½åŠ©æ‰‹")
    print("   æŒ‰ Ctrl+C é€€å‡º\n")

    return pipeline, transport, wake_system, mcp


async def run_pipeline_with_audio(pipeline, transport):
    """
    è¿è¡Œ Pipeline å¹¶å¤„ç†éŸ³é¢‘ I/O

    é…ç½®å®˜æ–¹ä¸­æ–­æ”¯æŒï¼š
    - ä½¿ç”¨ PipelineParams å¯ç”¨ allow_interruptions
    - éŸ³é¢‘è¾“å…¥é€šè¿‡ queue_frames() æ¨é€åˆ° Pipeline
    """
    from pipecat.frames.frames import StartFrame, EndFrame

    try:
        # âœ… åˆ›å»º PipelineTaskï¼Œé…ç½®å®˜æ–¹ä¸­æ–­æ”¯æŒ
        task = PipelineTask(
            pipeline,
            params=PipelineParams(
                allow_interruptions=True,  # å¯ç”¨å®˜æ–¹ä¸­æ–­æœºåˆ¶
                audio_in_sample_rate=16000,
                audio_out_sample_rate=16000,
            )
        )

        # å‘é€ StartFrame åˆå§‹åŒ–
        await task.queue_frames([StartFrame()])

        # åˆ›å»ºéŸ³é¢‘è¾“å…¥ä»»åŠ¡
        async def audio_input_loop():
            """æŒç»­è¯»å–éŸ³é¢‘å¹¶æ¨é€åˆ° Pipeline"""
            async for audio_frame in transport.read_audio_frames():
                await task.queue_frames([audio_frame])

        # åˆ›å»º PipelineRunner å¹¶è¿è¡Œ
        runner = PipelineRunner()

        # åˆ›å»ºéŸ³é¢‘è¾“å…¥ä»»åŠ¡ï¼ˆä½œä¸ºåå°ä»»åŠ¡ï¼‰
        audio_task = asyncio.create_task(audio_input_loop())

        try:
            # è¿è¡Œ Pipelineï¼ˆä¸»ä»»åŠ¡ï¼‰
            await runner.run(task)
        finally:
            # Pipeline ç»“æŸæ—¶ï¼Œå–æ¶ˆéŸ³é¢‘è¾“å…¥ä»»åŠ¡
            audio_task.cancel()
            try:
                await audio_task
            except asyncio.CancelledError:
                pass

    except asyncio.CancelledError:
        # å‘é€ EndFrame ç»“æŸ
        try:
            await task.queue_frames([EndFrame()])
        except:
            pass
        print("\nâ¹ï¸  Pipeline å·²åœæ­¢")
        raise  # é‡æ–°æŠ›å‡ºå¼‚å¸¸ï¼Œè®© main() å¤„ç†
    except Exception as e:
        print(f"\nâŒ Pipeline è¿è¡Œé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        raise  # é‡æ–°æŠ›å‡ºå¼‚å¸¸


async def main():
    """Pipecat ä¸»ç¨‹åº - æ··åˆæ¶æ„ç‰ˆ"""
    pipeline = None
    transport = None
    wake_system = None
    mcp = None

    try:
        # åˆ›å»º Pipelineï¼ˆæ··åˆæ¶æ„ï¼‰
        pipeline, transport, wake_system, mcp = await create_pipecat_pipeline()

        # è¿è¡Œ Pipelineï¼ˆè®© Pipecat å¤„ç† Ctrl+Cï¼‰
        await run_pipeline_with_audio(pipeline, transport)

    except KeyboardInterrupt:
        print("\nâ¹ï¸  æ”¶åˆ°é€€å‡ºä¿¡å·...")
    except asyncio.CancelledError:
        print("\nâ¹ï¸  Pipeline å·²å–æ¶ˆ")
    except Exception as e:
        print(f"\nâŒ å¯åŠ¨å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()

    finally:
        # æ¸…ç†èµ„æº
        print("\nğŸ§¹ æ­£åœ¨æ¸…ç†èµ„æº...")

        # 1. åœæ­¢éŸ³é¢‘ä¼ è¾“
        if transport:
            try:
                await transport.stop()
                print("  âœ“ éŸ³é¢‘ä¼ è¾“å·²åœæ­¢")
            except Exception as e:
                print(f"  âš ï¸ åœæ­¢éŸ³é¢‘ä¼ è¾“æ—¶å‡ºé”™: {e}")

        # 2. åœæ­¢ MCP Servers
        if mcp:
            try:
                await mcp.stop_all_async()
                print("  âœ“ MCP Servers å·²åœæ­¢")
            except Exception as e:
                print(f"  âš ï¸ åœæ­¢ MCP Servers æ—¶å‡ºé”™: {e}")

        print("\nğŸ‘‹ å†è§ï¼")


if __name__ == "__main__":
    asyncio.run(main())

"""æ™ºèƒ½è¯­éŸ³å”¤é†’ç³»ç»Ÿ - æ¨¡å‹åŠ è½½å™¨ï¼ˆç”¨äº Pipecat æ¨¡å¼ï¼‰"""
import numpy as np
import sherpa_onnx
from pathlib import Path

from .config import (
    MODELS_DIR,
    SAMPLE_RATE,
    DEFAULT_WAKE_WORDS,
    CONFIG_DIR,
)
from .react_agent import ReactAgent


class SmartWakeWordSystem:
    """æ™ºèƒ½è¯­éŸ³å”¤é†’ç³»ç»Ÿ - æ¨¡å‹åŠ è½½å™¨ï¼ˆä»…ç”¨äº Pipecat æ¨¡å¼ï¼‰"""

    def __init__(self, models_dir=None, enable_voice=False, enable_mcp=False):
        """
        åˆå§‹åŒ–è¯­éŸ³åŠ©æ‰‹æ¨¡å‹åŠ è½½å™¨

        Args:
            models_dir: æ¨¡å‹ç›®å½•è·¯å¾„
            enable_voice: å¯ç”¨è¯­éŸ³æ’­æŠ¥ï¼ˆPipecat æ¨¡å¼ä¸­ç”± TTS Processor å¤„ç†ï¼‰
            enable_mcp: å¯ç”¨ MCPï¼ˆPipecat æ¨¡å¼ä¸­å°†å¼‚æ­¥å¯åŠ¨ï¼Œæ­¤å‚æ•°è¢«å¿½ç•¥ï¼‰
        """
        self.models_dir = Path(models_dir) if models_dir else MODELS_DIR
        self.sample_rate = SAMPLE_RATE

        print("æ­£åœ¨åˆå§‹åŒ–æ™ºèƒ½è¯­éŸ³åŠ©æ‰‹...")

        # é˜¶æ®µ1: KWSæ¨¡å‹ï¼ˆè½»é‡çº§ï¼‰
        self.kws_model = self.create_kws_model()

        # é˜¶æ®µ2: ASRæ¨¡å‹ï¼ˆé‡é‡çº§ï¼‰
        self.asr_model = self.create_asr_model()

        # React Agentï¼ˆMCP å°†åœ¨ Pipecat æ¨¡å¼ä¸­å¼‚æ­¥å¯åŠ¨ï¼‰
        self.agent = ReactAgent()

        print(f"âœ“ KWSæ¨¡å‹å·²åŠ è½½")
        print(f"âœ“ ASRæ¨¡å‹å·²åŠ è½½")
        print(f"âœ“ React Agent å·²åˆ›å»ºï¼ˆMCP å°†ç¨åå¼‚æ­¥å¯åŠ¨ï¼‰")

    def create_kws_model(self):
        """åˆ›å»ºKWSå…³é”®è¯æ£€æµ‹æ¨¡å‹"""
        kws_dir = self.models_dir / "sherpa-onnx-kws-zipformer-wenetspeech-3.3M-2024-01-01"

        if not kws_dir.exists():
            raise FileNotFoundError(f"KWSæ¨¡å‹ç›®å½•ä¸å­˜åœ¨: {kws_dir}")

        # åˆ›å»ºå…³é”®è¯æ–‡ä»¶ï¼ˆæ ¼å¼ï¼šæ‹¼éŸ³éŸ³èŠ‚ @ä¸­æ–‡ï¼‰
        keywords_file = CONFIG_DIR / "keywords.txt"
        if not keywords_file.exists():
            print("âš ï¸  åˆ›å»ºé»˜è®¤å…³é”®è¯æ–‡ä»¶...")
            keywords_file.parent.mkdir(parents=True, exist_ok=True)
            with open(keywords_file, 'w', encoding='utf-8') as f:
                # æ ¼å¼ï¼šæ‹¼éŸ³éŸ³èŠ‚(ç©ºæ ¼åˆ†éš”) @ä¸­æ–‡
                # ä½¿ç”¨å¸¦å£°è°ƒçš„æ‹¼éŸ³éŸµæ¯ï¼Œç©ºæ ¼åˆ†éš”
                f.write("x iÇo zh Ã¬ @å°æ™º\n")
                f.write("n Ç h Ço zh Ã¹ sh Ç’u @ä½ å¥½åŠ©æ‰‹\n")
                f.write("zh Ã¬ n Ã©ng zh Ã¹ sh Ç’u @æ™ºèƒ½åŠ©æ‰‹\n")

        kws = sherpa_onnx.KeywordSpotter(
            tokens=str(kws_dir / "tokens.txt"),
            encoder=str(kws_dir / "encoder-epoch-12-avg-2-chunk-16-left-64.onnx"),
            decoder=str(kws_dir / "decoder-epoch-12-avg-2-chunk-16-left-64.onnx"),
            joiner=str(kws_dir / "joiner-epoch-12-avg-2-chunk-16-left-64.onnx"),
            num_threads=2,
            keywords_file=str(keywords_file),
            provider="cpu",
        )

        print(f"ğŸ“‹ åŠ è½½å…³é”®è¯: {keywords_file}")
        return kws

    def create_asr_model(self):
        """åˆ›å»ºASRå®Œæ•´è¯†åˆ«æ¨¡å‹"""
        model_file = self.models_dir / "sherpa-onnx-paraformer-zh-2024-03-09" / "model.int8.onnx"
        tokens_file = self.models_dir / "sherpa-onnx-paraformer-zh-2024-03-09" / "tokens.txt"

        if not model_file.exists():
            raise FileNotFoundError(f"ASRæ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_file}")

        recognizer = sherpa_onnx.OfflineRecognizer.from_paraformer(
            str(model_file),
            str(tokens_file),
            num_threads=2,
            sample_rate=self.sample_rate,
            feature_dim=80,
            decoding_method="greedy_search",
            debug=False,
            provider="cpu"
        )
        return recognizer
